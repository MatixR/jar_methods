\section{Causal inference in accounting research}

\subsection{Causal inference in accounting research}
To get a sense for the importance of causal questions in accounting research,
we conducted a survey of all papers published in 2014 in the  \textit{Journal of Accounting Research}, \textit{The Accounting Review}, or the \textit{Journal of Accounting and Economics}).
We counted 139 papers, of which, 
125 are original research papers 
(a further 4 and
[10] papers survey [discuss] other
papers).

We assign a category to each original research paper based on the methods used in the paper: ``theoretical''  (7), ``experimental'' (12), ``field" (3), or ``empirical"  (103).
% Would "archival" be a better term for "empirical?
We then examine the research questions asked in each non-theoretical paper and
ask whether the primary or secondary research questions in each paper are
``causal" in nature.

Of the  103 original, empirical papers, we coded 90 as seeking to draw causal inferences. Of the remaining empirical papers, we coded 5 papers as having a goal of ``description.'' 
For example, \citet{Soltes:2013ba} uses data collected from one firm to provide insights into when analysts privately interact with management the nature of these interactions.
We coded 5 papers as having a goal of ``prediction.'' 
For example, \citet{Czerney:2014bv} examine whether the inclusion of ``explanatory language" in unqualified audit reports can be used to predict the detection of financial misstatements in the future.
We coded 3 papers as having a goal of ``measurement.'' 
For example, \citet{Cready:2014ji} examine whether inferences about traders based on trade size are reliable and suggest improvements to the measurement of variables used by accounting researchers. 

In coding 90 papers as seeking to draw causal inferences, we generally examined the title and
abstract for evidence of causal inference. Often the title reveals a causal question, with words such as  ``effect of \dots" or ``impact of \dots"  
\citep[e.g.][]{Cohen:2014jl,Clorproell:2014cv} making it clear that a causal question was being asked. 
Often language in the abstract reveals a goal of causal inference. For example, \citet{deFranco:2014ct} asks ``how the tone of sell-side debt analysts’ discussions about debt-equity conflict events \emph{affects} the informativeness of debt analysts’ reports in debt markets.''

\subsection{Where do research questions come from?}
One striking aspect of 

\subsection{The role of theory in empirical accounting research}
The vast majority of empirical research papers in accounting do not rely on a formal theoretical model to motivate their hypotheses.
This is perhaps inevitable given the wide range of theories that accounting researchers study, and the inherent complexity of many of the treatment and outcome variables.
For example, \citet{Huang:2014cs} study the effect ``tone management'' on capital market outcomes.
Developing a formal theory of the relation between firm performance, managerial psychological states, and measures of tone would be a complex undertaking involving economics, psychology, and linguistics.
Building on such a (hypothetical) foundation to solve the complex game involving managers and capital markets would be extremely ambitious.
Instead, \citet{Huang:2014cs} does what almost all empirical research papers in accounting do and resorts to ``verbal theorizing'.'


\subsection{Endogeneity}

\section{Quasi-experimental methods in accounting research}

\subsection{Natural experiments}
Natural experiments occur when observations are assigned by nature (or some other force outside the control of the researcher) to treatment and control groups in a way that is random or ``as if'' random \citep{Dunning:2012tt}. 
Truly (as if) random assignment to treatment and control provides a sound basis for causal inference, enhancing the appeal of natural experiments.
However, \citet{Dunning:2012tt} argues that this appeal ``may provoke conceptual stretching, in which an attractive label is applied to research designs that only implausibly meet the definitional features of the method'' \citep[p.3]{Dunning:2012tt}.

Such ``conceptual stretching'' is evident in accounting research.
Our survey of accounting research identified six papers that exploited either a ``natural experiment'' or ``exogenous shock'' to identify causal effects \citep{Lo:2013jk,Aier:2014ii,Kirk:2014gx,Houston:2014hv}. % Wtat about Hail:2014fq?
But closer examination suggests that most of these papers misapply the fundamental idea of natural experiments.

\cite{Aier:2014ii} exploit a 1991 Delaware court that ``expanded the scope of directors' fiduciary duties to include creditors when a Delaware incorporated firm is in the `vicinity of insolvency.'" as a ``natural experiment'' for the purpose of understanding the causal effect of debtholders' demand for conservatism (the treatment variable) on financial reporting conservatism (the outcome of interest). But it is completely unclear how this ``natural experiment'' sorted firms into differing levels of the treatment variable, let alone why this assignment is as-if random.

 \citet{Kirk:2014gx} ``exploit the natural experiment setting created by the exogenous shock of Reg FD to examine the effect of Reg FD on firms with an established IR [investor relations] program.'' 
Given that the treatment of interest in \citet{Kirk:2014gx} is the establishment of an IR program, only a event that randomly assigned firms to having or not having such a program would qualify as a natural experiment in that setting.

\cite{Houston:2014hv} analyzes ``whether the political connections of listed firms in the United States affect the cost and terms of loan contracts'.' They argue that ``the recent financial crisis can be viewed as a major exogenous shock, the effects of which may vary depending on whether the firm is politically connected.'' But this is not what is needed for a valid natural experiment. To see this, an analogy is perhaps helpful. Suppose we wanted to study the effects of smoking on life expectancy. A long-standing concern in studies of such effects is the existence of other differences in the lifestyles of smokers and non-smokers. A ``natural experiment'' analogous to that in \cite{Houston:2014hv} might be one that created gas leaks in the homes of smokers and non-smokers alike. Because gas leaks are likely to have more deleterious consequences on smokers (e.g., instant immolation when lighting a cigarette), the reasoning of \cite{Houston:2014hv} might suggest that gas leaks are a helpful ``exogenous shock,'' contrary to common sense.

A plausible explanation for the ease with which conceptual stretching has occurred derives from the ambiguity of the word ``exogenous,'' which not only denotes  ``of, relating to, or developing from external factors'' (Oxford Dictionary), but is also the antonym of ``endogenous.''
For example, the fact that Reg FD was perhaps not driven by factors related to firms' IR programs and firm-level capital market outcomes, it does not randomly assign firms into treatment and control groups and thus does not help resolve the endogeneity of IR programs with such capital market outcomes.

% IV starts here!
\subsection{Instrumental variables}
\citet[p.114]{Angrist:2008vk} describe instrumental variables (IV) as ``the most powerful weapon in the arsenal of [statistical tools]" in econometrics. 
Accounting researchers have long used instrument variables to address concerns about endogeneity \citep{Larcker:2010fq} and continue to do so: our survey of research published in 2014 identifies 10 papers using instrumental variables \citep{Cannon:2014im,Cohen:2014jl,Kim:2014fm,Vermeer:2014bs,Fox:2014io,Guedhami:2013cj,Houston:2014hv,deFranco:2014ct,Erkens:2014hj,Correia:2014fp}. 

However, much has been written on the challenges for researchers in using instrumental variables (IV) as the basis for causal inference (e.g., Roberts and Whited (2012)). 
With respect to accounting research, \citet{Larcker:2010fq} lament that ``some researchers consider the choice of instrumental variables to be a purely statistical exercise with little real economic foundation'' and call for 
``accounting researchers \dots to be much more rigorous in selecting and justifying their instrumental variables.'' 
\citet[p.117]{Angrist:2008vk} argue that ``good instruments come from a combination of institutional knowledge and ideas about the process determining the variable of interest."
One study that illustrates this is \cite{Angrist:2008vk}.
In that setting, the draft lottery is well understood as random and the process of mapping from the lottery to draft eligibility is well understood.
Furthermore, there are good reasons to believe that the draft lottery does not affect anything else directly except for draft eligibility.

One popular source of instruments in accounting, finance, and economics is prior research in economics and finance.
\citet{Kelly:2012ih} seek to understand the effect of changes in analyst coverage on information asymmetry. 
The challenge faced by \citet{Kelly:2012ih} is that changes in analyst coverage are generally not random and may be correlated with information asymmetry due to omitted correlated variables.
\citet{Kelly:2012ih} treat mergers of brokerage firms that covered treatment firms as an exogenous (i.e., as-if random) source of variation in analyst coverage. \footnote{There are actually issues that could be raised with this instrument, but these are outside the scope of this paper.} They then examine the effect of such changes in analyst coverage on information asymmetry.

\citet{Balakrishnan:2014js} use the  ``exogenous shocks" to analyst coverage in \citet{Kelly:2012ih} as an instrument for changes in voluntary disclosure practices. As noted in \citet{Balakrishnan:2014js}, the critical identifying assumptions are that ``lagged coverage shocks a) lead to more disclosure, b) not affect liquidity directly, and c) not correlate with some omitted variable that in turn affects liquidity." But, if we assume that analyst coverage is sticky (i.e. that analyst coverage in $t$ affects analyst coverage in $t+1$), then the causal diagram in Figure \ref{fig:bbkl} shows why this assumption is implausible. 
The endogeneity concern in \citet{Kelly:2012ih}  is that contemporaneous analyst coverage and information asymmetry are plausibly correlated for non-causal reasons (or due to reverse causality). 
This is represented using a bidirectional dashed line between analyst coverage and information asymmetry.
But this dashed line is part of a backdoor path running from $\textit{Liquidity}_{t+1}$ to $\textit{Disclosure}$.

\begin{figure} \caption{Causal graph for \citet{Balakrishnan:2014js}} \label{fig:bbkl}
\begin{tikzpicture}[
	every node/.style = 
    	{shape = rectangle, rounded corners, fill = black!30!white,
   		text width = 3cm, minimum height = 1.5cm, align = center, text = black},
    black edge/.style = { -,  ultra thick, black, shorten >= 2pt}]
    %create X and Y node
    \node[rectangle] (BC) {Brokerage closure$_t$}; 
    \node [right = 1 of BC] (AC0) {Analyst coverage$_t$};
    \node [right = 1 of AC0] (AC1) {Analyst coverage$_{t+1}$};
    \node [below = 1 of AC0] (IA0) {Information asymmetry$_t$};
    \node [right = 1 of IA0] (IA1) {Information asymmetry$_{t+1}$};
    \node [below = 1 of IA0] (D) {Disclosure};
    \node [right = 1 of D] (LQ) {Liquidity$_{t+1}$};
    \draw (BC) edge[->] (AC0);
    \draw (AC0) edge[->] (IA0);
     \draw (AC0) edge[->] (AC1);
     \draw (AC1) edge[dashed, <->] (IA1);
    \draw (IA0) edge[->] (D);
    \draw (IA1) edge[->] (LQ);
    \draw (D) edge[->] (LQ);
    \draw (IA0) edge[bend right=60, dashed, <->] (AC0);
\end{tikzpicture}
\end{figure}




A review of these papers suggests that researchers have paid little heed to the suggestions and warnings of Roberts and Whited (2012) and \citet{Larcker:2010fq}. 

Several papers provide little or no justification for the validity of their instruments. For example, to address endogeneity \citet{Cohen:2014jl} use ``two instrumental variables. The first is the natural log of industry size, measured as the number of companies within each two-digit SIC. The second measures industry competition using the Herfindahl-Hirschman index, which is well-established as a measure of competitive industries. Our untabulated results using this approach are qualitatively similar to our main analysis, thus indicating that endogeneity is not a concern when assessing the reliability of our findings.''
\citet{Vermeer:2014bs} ``use Maddala's (1988) two-stage procedure'' in order to ``control for endogeneity'' without providing any explanation at all and in fact seem to be assuming the each of three endogeneous variables can used as an instrument for the other two.
\citet[p.48]{Fox:2014io} state in a footnote that they ``instrumented for the price index employing a two stage least squares estimator'' without further details, simply noting that their ``conclusions are robust with respect to these concerns.''
\citet{Cannon:2014im} uses ``industry-level capacity unit cost and selling price changes'' as instruments for firm-level capacity unit cost changes with no more justification than the fact that these ``are outside management's control.'' But being outside management control does not make a variable endogenous in an econometric sense.

Other papers provide limited, but seemingly flawed, justification for their chosen instruments. 
 \citet{Guedhami:2013cj} use $\textit{CAPITAL}$, an indicator for a firm being located in a capital city, as an instrument for political connectivity in a study looking at the effect of political connections on the use of a Big 4 auditor ($\textit{BIG 4}$).
 The only justification \citet{Guedhami:2013cj} provide in support of the required exclusion restriction  is that ``importantly, the correlation between $\textit{CAPITAL}$ and $\textit{BIG 4}$ is small in our data set $(\rho = 0.05)$, helping to justify the validity of this exclusion restriction.''
 \citet{Guedhami:2013cj} cite \citet{Larcker:2010fq} as a reference for this approach, even though \citet{Larcker:2010fq} carefully explain why simple tests like this cannot be used to justify instruments.
 \citet{Houston:2014hv} use variables variables that are related to the location of the company's headquarters as instruments for political connection and argue that ``these instruments should not be conceptually related to loan spreads. The key insight here is that the geographic locations of headquarters for companies are predetermined and are unlikely to affect banks' financing decision on loan costs. In summary, our identification assumption is that the costs of bank loans are not directly related to the companies' geographic locations, after controlling for a series of firm and loan characteristics'' (p.228). In effect the authors express the necessary condition in various words three times, but do not justify it in any meaningful way.
 There is an asymmetry evident in the reasoning of \citet{Houston:2014hv}. In justifying the relevance of the instrument, the authors seem eager to justify a connection, suggesting that ``the presumption is that the company's geographic location affects the company's ability to attract politically connected directors.'' But it far from clear why a company's geographic location would not also affect the its ability to attract directors with connections to \emph{financial institutions}, which plausibly affects financing terms directly \citep{Guner:2008tp}.\footnote{\citet{Houston:2014hv} also use firm age as an instrument, arguing that ``firm age affects a firm's incentive and capability in building up political connections''; but it is not clear why firm age would not also affect a firm's ``incentive and capability in building up'' financial connections.} 
 
 Many instruments considered by researchers are arguably obscure in that the factors that determine the instrument are unclear (yet very unlikely to be random) and the relation between the instrument and the endogenous variable for which it is an instrument is nebulous, making it difficult to rule out the possibility that the instrument directly affects (or is correlated with) variables other than the endogenous variable of interest.	
 \citet{Erkens:2014hj} ``use the following three instrumental variables that capture the extent to which lenders are more likely to serve on a firm's board, which is studied for its potential effect on accounting conservatism. We use \emph{Industry importance to primary lender} because industry specialization increases the importance of acquiring information about a firm's industry, \emph{Primary lender within 50 mile radius} because physical proximity to lenders' headquarters reduces the cost of serving on the board, and \emph{Number of commercial banks within 50 mile radius} because the close proximity of multiple banks increases competition for board seats from other lenders.'' If industry specialization affects information-acquisition incentives, it seems it would do so through channels outside of board membership. With respect to the second instrument, it's quite likely that proximity affects information-gathering independent of service on the board. With respect to the third instrument, it is also implausible that the only direct effect of this variable is one on the service of bankers on the board (for example, this may lead to lower search costs in choosing potential lenders.
 
In some cases, arguments that seek to justify a set of instruments seem to provide reasons to believe that they \emph{not} valid. \citet{Kim:2014fm} use director age as an instrument for director tenure in a study examining the effect of the latter on firm performance. 
``Importantly, research finds little or no association between age and performance \dots and a small negative association between age and executive functions \dots. 
Related to directors, Ferris et al. (2003) suggest that any positive effects from director experience increasing with age may be offset by older directors having less energy, posing a last-period risk, and viewing directorships as lucrative part-time jobs for their retirement years.'' 
But these arguments seem to invalidate age as an instrument for tenure. 
For age to be a valid instrument, there should be no unblocked causal path between age and performance except for the path via tenure.
 That possible positive effects may be offset by negative effects and thus detecting an association between age and performance is not a valid basis for claiming age to be a valid instrument. \citet{deFranco:2014ct} ``find that the number of covenants is positively related to the interest rate, likely due to endogeneity between the interest rate and covenants.'' To address this using they use ``the number of covenants by calendar year indicators as the instrument'' for the number of covenants. Apart from the issues with using an average as an instrument discussed in \citet{Reiss:2007ej}, the authors justify their instrument by suggesting that ``the strictness of covenant packages significantly deteriorated during the years of the credit boom that preceded the financial crisis.'' But it seems likely that the credit boom would have a direct effect on interest rates on bond issues. 
 
\citet{Correia:2014fp} uses ``average level of political contributions made by the other firms in the same industry'' as an instrument for political contributions by a firm, as well as two additional instruments: ``the percentage of sales made to the government, and the number of years in the previous five years in which there was a close election involving two candidates in the firm's state.'' With regard to the first instrument, the reasons that cause political contributions to be endogenous may well affect all firms in an industry (or at least be correlated across firms within an industry). 
As such \citet{Reiss:2007ej} suggest that there is little reason to view such averages as valid instruments.

One feature of \citet{Correia:2014fp} is that the analysis of IV is thorough relative to most of the papers discussed above.  \citet{Correia:2014fp} tests for weak instruments and also uses a test of over-identifying restrictions to examine the validity of her chosen instruments. 
But these tests arguably very little assurance.
To see this, suppose that we have $y = X \beta + \epsilon$, but with $X$ and $\epsilon$ having correlation $\rho(X, \epsilon) = 0.2$ and $\beta = 0$ (i.e., there is no causal relation between $X$ and $y$). Clearly we have an endogeneity issue as $\rho(X, \epsilon) > 0$. 
Now, suppose we construct the following three instruments 
$z_1 = x + \eta_1$, $z_2 = \eta_2$, and $z_3 = \eta_3$, with $\sigma_{\eta_1} = \sigma_{\eta_2} = \sigma_{\eta_3} \sim N(0, 0.09)$ and independent. 
That is, $z_1$ is $X$ plus noise, while $z_2$ and $z_3$ are random noise.

Assuming that $X$ and $\epsilon$ are bivariate-normally distributed with variance of $1$, we can run 1000 simulations and  run IV regression using these instruments on the simulated data in each case. Doing so, we find:
\begin{itemize}
\item A mean estimated coefficient on $X$ is $0.201$, which is statistically significant at the
5\% level 100\% of the time. 
Note that this coefficient is close to $\rho(X, \epsilon) = 0.2$, which is to be expected given how our data were generated.
\item Based on a test statistic of 30, which easily exceeds the thresholds suggested by Stock et al. (2002), the null hypothesis of weak instruments is rejected 100\% of the time. 
\item The test of overidentifying restrictions fails to reject a null hypothesis of valid instruments (at the 5\% level) 95.7\% of the time.
\end{itemize}

In other words, it is easy for completely spurious instruments to deliver bad inferences, yet easily pass tests for weak instruments and endogeneity.

\subsection{Regression discontinuity designs} 
%\textbf{TBD.} Discuss RD d, how it works, but issues in applying it and the fact that it has limited applicability in general (i.e., need a discontinuity).

In discussing the recent ``flurry of research" using regression discontinuity (RD) designs, \citet[p.282]{Lee:2010hya} point out that they ``require seemingly mild assumptions compared to those needed for other nonexperimental approaches \dots and that causal inferences from RD designs are potentially more credible than those from typical `natural experiment' strategies." 
Recently, RD designs have attracted the interest of accounting researchers, as a number of phenomena of interest to accounting researchers involve discontinuities. For example, whether an executive compensation plan is approved is a discontinuous function of shareholder support \citet{Armstrong:2013io} and whether a firm had to comply with provisions of Sarbanes-Oxley Act in 2004 \citep{Iliev:2010ic}.

While RD designs make relatively mild assumptions, in practice these assumptions may be violated. In particular, manipulation of the running variable may occur.

It is also important to note that various ``quasi-RD" designs bear little resemblance to RD designs.
% Listokin, McCrary, etc.

\subsection{Propensity score matching}

Should we discuss this too? PSM is not really a ``quasi-experimental'' method in the sense of the above methods except under assumptions that are about as restrictive as those needed to deliver causal estimates using OLS (basically OLS without linearity). That is, it does \emph{not} solve endogeneity, but many believe that it does.

\subsection{Overall evaluation} 
\textbf{TBD.} Quasi-experimental methods are very poorly applied by accounting researchers. Even if accounting researchers knew what they were doing, the reality is that instruments, natural experiments, and discontinuities do not grow on trees. So quasi-experimental methods are unlikely to deliver anything like the 100+ papers that accounting researchers crank out every year (in economics---a much broader field---it's the same handful of examples brought out over and over).

The next part of the paper has a more positive take (structural modeling, etc.).

\newpage

Likely effective in settings, but of limited applicability and care is needed to do it well and to interpret the results. Discuss examples from shareholder voting and the \$75 million threshold for SOX.



\subsection{Overall assessment}

We agree that the revolution in econometric methods for causal inference has certainly been an exciting development.\footnote{Not sure about ``revolution''; need to look at \emph{Mostly Harmless Econometrics} to get the right term here.} However, we have two grave concerns with regard to this methods in accounting research. First, it is evident that accounting researchers understand these methods only poorly and frequently seek to apply them inappropriately. Second,  it is far from clear that these methods, properly applied, can support more than a tiny fraction of accounting research. Of more than a 100 papers published in the top three accounting journals in 2014, we identified just a small fraction that applied these approaches and the vast majority of these did so in ways that seem difficult to classify as appropriate. Accounting researchers license to run IV should be revoked.

