\documentclass{article}
\usepackage[marginratio=1:1]{geometry}  % See geometry.pdf to learn the layout options. There are lots.
%\geometry{letterpaper} % ... or a4paper or a5paper or ... 
%\geometry{landscape}  % Activate for for rotated page geometry
\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
%\usepackage{amsfonts}
\usepackage{palatino}
\usepackage{natbib}
\usepackage{hyperref} 

\begin{document}

<<set_parameters, include=FALSE>>=
n <- 1000
beta <- 0

library("MASS")
corr <- 0.2
Sigma <- matrix(c(1, corr, corr, 1), nrow=2)

sd_eta <- 0.3
# cor(df$X, df$e)
@

<<generate_data, include=FALSE>>=
generate_data <- function() {
    X <- rnorm(n)
    df <- data.frame(mvrnorm(n, mu=c(0,0), Sigma=Sigma))
    names(df) <- c("X", "e")
    df$y <- df$X * beta + df$e

    df$z_1 <- df$X + rnorm(n, sd=sd_eta)
    df$z_2 <- rnorm(n, sd=sd_eta)
    df$z_3 <- rnorm(n, sd=sd_eta)
    return(df)
}

@
Suppose that we have $y = X \beta + \epsilon$, 
with $\rho(X, \epsilon) = \Sexpr{corr}$ and $\beta = \Sexpr{beta}$.
Clearly we have an endogeneity issue as $\rho(X, \epsilon) > 0$. 

But, wait. There's a solution!

\emph{Create} three instruments: 
$z_1 = x + \eta_1$, $z_2 = \eta_2$, and $z_3 = \eta_3$,
where $\sigma_{\eta_1} = \sigma_{\eta_2} = \sigma_{\eta_3} \sim N(0,\Sexpr{sd_eta^2})$ and independent.

What happens when we estimate IV using these instruments?
<<run_iv, message=FALSE, echo=FALSE, results="asis">>==
run_simulation <- function(run) {
    library("AER")
    df <- generate_data()
    iv <- ivreg(y ~ X | z_1 + z_2 + z_3, data = df)
    iv.sum <- summary(iv, diagnostics=TRUE)
    
    return(c(
        run = run,
        coeff = iv.sum$coefficients["X", 1],
        p.value = iv.sum$coefficients["X", 4],
        Sargan.stat = iv.sum$diagnostics["Sargan", "statistic"],
        Sargan.p = iv.sum$diagnostics["Sargan", "p-value"],
        F.stat = iv.sum$diagnostics["Weak instruments", "statistic"],
        F.p = iv.sum$diagnostics["Weak instruments", "p-value"]))
}

k <- 1000
library(parallel)
sim_results <- as.data.frame(do.call("rbind", mclapply(1:k, run_simulation)))

# library("stargazer")
# stargazer(iv)
p.cutoff <- 0.05
F.threshold <- 30
coeff <- prettyNum(mean(sim_results$coeff), digits=3)
sig.percent <- prettyNum(mean(sim_results$p.value < p.cutoff)*100)
F.stat <- prettyNum(mean(sim_results$F.stat > F.threshold)*100)
reject.endogeneity <-  prettyNum(mean(sim_results$Sargan.p >= p.cutoff)*100)
@
Assuming that $X$ and $\epsilon$ are bivariate-normally distributed with variance $1$, I ran \Sexpr{prettyNum(k)} simulations and got the following:

\begin{itemize}
\item The mean estimated coefficient on $X$ is \Sexpr{coeff}, which is statistically significant at the
\Sexpr{paste0(p.cutoff*100, "\\%")} level \Sexpr{paste0(sig.percent, "\\%")} of the time. 
Note that this coefficient is close to $\rho(X, \epsilon) = \Sexpr{corr}$, which is to be expected given how our data were generated.
\item Based on a test statistic of \Sexpr{F.threshold}, which easily exceeds the thresholds suggested by Stock et al. (2002), the null hypothesis of weak instruments is rejected \Sexpr{paste0(F.stat, "\\%")} of the time. 
\item The test of overidentifying restrictions fails to reject a null hypothesis of valid instruments
(at the \Sexpr{paste0(p.cutoff*100, "\\%")} level)
\Sexpr{paste0(reject.endogeneity, "\\%")} of the time.
\end{itemize}

Hooray!

\end{document}